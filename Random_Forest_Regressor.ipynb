{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Random Forest Regressor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit ('env': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "0111817ea0767685089815a8346b7ddb44dc6686759b000d5a9694abd8ceb5ac"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 30 Days of ML Competition\n",
        "---"
      ],
      "metadata": {
        "id": "Ok47I272TGWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Import Libraries**"
      ],
      "metadata": {
        "id": "i7_V_KauUKsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#!pip install numpy pandas scikit-learn xgboost keras --quiet"
      ],
      "outputs": [],
      "metadata": {
        "id": "v35wezvpSJDJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score, KFold,\r\n",
        "                                     RandomizedSearchCV)\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "\r\n",
        "from xgboost import XGBRegressor\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "INYJMKCNTN1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Step 2: Load the Data**\n"
      ],
      "metadata": {
        "id": "KcsIaChVUTf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "# Load the training data:\r\n",
        "training_df = pd.read_csv(\"data/train.csv\", index_col=0)\r\n",
        "testing_df = pd.read_csv(\"data/test.csv\", index_col=0)\r\n",
        "\r\n",
        "# Preview the data:\r\n",
        "print(training_df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont5     cont6  \\\n",
            "id                                                    ...                       \n",
            "1     B    B    B    C    B    B    A    E    C    N  ...  0.400361  0.160266   \n",
            "2     B    B    A    A    B    D    A    F    A    O  ...  0.533087  0.558922   \n",
            "3     A    A    A    C    B    D    A    D    A    F  ...  0.650609  0.375348   \n",
            "4     B    B    A    C    B    D    A    E    C    K  ...  0.668980  0.239061   \n",
            "6     A    A    A    C    B    D    A    E    A    N  ...  0.686964  0.420667   \n",
            "\n",
            "       cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
            "id                                                                         \n",
            "1   0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n",
            "2   0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n",
            "3   0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n",
            "4   0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n",
            "6   0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n",
            "\n",
            "      target  \n",
            "id            \n",
            "1   8.113634  \n",
            "2   8.481233  \n",
            "3   8.364351  \n",
            "4   8.049253  \n",
            "6   7.972260  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51JC1MlbUZeD",
        "outputId": "75a3cc3f-d515-4459-d2a7-6def6b99710f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "source": [
        "\r\n",
        "# Seperate the Data from the Target:\r\n",
        "y = training_df[\"target\"]\r\n",
        "features = training_df.drop([\"target\"], axis=1)\r\n",
        "\r\n",
        "# Drop additonal features:\r\n",
        "dropped_features = [\"cat0\", \"cat2\", \"cat3\", \"cat4\", \"cat6\", \"cat7\", 'cat9']\r\n",
        "features = features.drop(dropped_features, axis=1)\r\n",
        "\r\n",
        "\r\n",
        "print(features.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cat1 cat5 cat8     cont0     cont1     cont2     cont3     cont4     cont5  \\\n",
            "id                                                                              \n",
            "1     B    B    C  0.201470 -0.014822  0.669699  0.136278  0.610706  0.400361   \n",
            "2     B    D    A  0.743068  0.367411  1.021605  0.365798  0.276853  0.533087   \n",
            "3     A    D    A  0.742708  0.310383 -0.012673  0.576957  0.285074  0.650609   \n",
            "4     B    D    C  0.429551  0.620998  0.577942  0.280610  0.284667  0.668980   \n",
            "6     A    D    A  1.058291  0.367492 -0.052389  0.232407  0.287595  0.686964   \n",
            "\n",
            "       cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
            "id                                                                         \n",
            "1   0.160266  0.310921  0.389470  0.267559  0.237281  0.377873  0.322401   \n",
            "2   0.558922  0.516294  0.594928  0.341439  0.906013  0.921701  0.261975   \n",
            "3   0.375348  0.902567  0.555205  0.843531  0.748809  0.620126  0.541474   \n",
            "4   0.239061  0.732948  0.679618  0.574844  0.346010  0.714610  0.540150   \n",
            "6   0.420667  0.648182  0.684501  0.956692  1.000773  0.776742  0.625849   \n",
            "\n",
            "      cont13  \n",
            "id            \n",
            "1   0.869850  \n",
            "2   0.465083  \n",
            "3   0.763846  \n",
            "4   0.280682  \n",
            "6   0.250823  \n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5AgJfZJVmza",
        "outputId": "507b0ef1-8cc3-4fa2-c875-ff7048e9c7cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Step 3: Prepare the Data**"
      ],
      "metadata": {
        "id": "jg1-Lf-zWJx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seperate Our Variable Types:"
      ],
      "metadata": {
        "id": "GHl8lcveYdP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "source": [
        "# List of the categorical columns:\r\n",
        "#categorical_cols = [col for col in features.columns if 'cat' in col]\r\n",
        "categorical_cols = ['cat1', 'cat5', 'cat8']\r\n",
        "\r\n",
        "# Remove any category columns with little importance:\r\n",
        "#categorical_cols.remove('col_name')\r\n",
        "\r\n",
        "#-----------------------------------------------------------------------\r\n",
        "\r\n",
        "# List of the numerical columns:\r\n",
        "number_cols = [col for col in features.columns if 'cat' not in col]\r\n",
        "\r\n",
        "# Remove any columns here:\r\n",
        "#number_cols = number_cols.remove('col_name')"
      ],
      "outputs": [],
      "metadata": {
        "id": "VKFo3aEZWO_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Preproprocessing Transformers"
      ],
      "metadata": {
        "id": "AkHORuzuYjnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "source": [
        "# Preprocess categorical data:\r\n",
        "category_transformer = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('imputer', SimpleImputer(strategy='most_frequent')),\r\n",
        "      ('ordinal', OrdinalEncoder()),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "# Preprocess numerical data:\r\n",
        "number_transformer = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('simple', SimpleImputer(strategy='constant')),\r\n",
        "    ]\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "WH-o1zczYg2B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "source": [
        "# Combine the preprocessing steps into column transformer:\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "      ('cat', category_transformer, categorical_cols),\r\n",
        "      ('num', number_transformer, number_cols),\r\n",
        "    ]\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Oy-VqAyhZ74T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Copy Our DataFrames"
      ],
      "metadata": {
        "id": "AYbiLJlZaH7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "source": [
        "X = features.copy()\r\n",
        "X_test = testing_df.copy()\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "KFG_FJvTaMrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the Data Into Training & Validation Sets"
      ],
      "metadata": {
        "id": "FlpqGgLgaWpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "source": [
        "# Split data:\r\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(\r\n",
        "    X, y,\r\n",
        "    test_size=0.25,\r\n",
        "    random_state=0\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "SavCpBIuabO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Step 4: Setting Up & Training the Model**"
      ],
      "metadata": {
        "id": "cIuOmR1cbGu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "source": [
        "# Define the model + parameters:\r\n",
        "model = RandomForestRegressor()\r\n",
        "\r\n",
        "\r\n",
        "# Define option parameters for random search:\r\n",
        "params = {\r\n",
        "    'n_estimators': [300],\r\n",
        "    'max_features': ['sqrt'],\r\n",
        "    'max_depth': [20, 30, 40, 50, None],\r\n",
        "    'min_samples_split': [10],\r\n",
        "    'min_samples_leaf': [8],\r\n",
        "    'bootstrap': [True],\r\n",
        "}\r\n",
        "\r\n",
        "random_search_cv = RandomizedSearchCV(\r\n",
        "    estimator=model,\r\n",
        "    param_distributions=params,\r\n",
        "    n_iter=25,\r\n",
        "    scoring='neg_root_mean_squared_error',\r\n",
        "    cv=3,\r\n",
        "    verbose=2,\r\n",
        "    random_state=0,\r\n",
        "    n_jobs=10\r\n",
        ")\r\n",
        "'''\r\n",
        "Fitting 3 folds for each of 18 candidates, totalling 54 fits\r\n",
        "{'n_estimators': 300, 'min_samples_split': 10, 'max_features': 'sqrt'}\r\n",
        "'''\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nFitting 3 folds for each of 18 candidates, totalling 54 fits\\n{'n_estimators': 300, 'min_samples_split': 10, 'max_features': 'sqrt'}\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "metadata": {
        "id": "Mcc6HC8UbQ8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "source": [
        "# Preprocess training data:\r\n",
        "X_preprocessed = preprocessor.fit_transform(X_train)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "QKUVyR5ss2_L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "source": [
        "# Fit the Random Search model:\r\n",
        "random_search_cv.fit(X_preprocessed, y_train)\r\n",
        "\r\n",
        "# See the best params from fitting the random search:\r\n",
        "print(random_search_cv.best_params_)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 5 is smaller than n_iter=25. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "{'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp_-7WnroBMO",
        "outputId": "f2c97d6d-89a6-4e16-f98c-d05485df28c5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "source": [
        "# Evaluate the random search model:\r\n",
        "def evaluate(model, test_features, test_labels):\r\n",
        "  predictions = model.predict(test_features)\r\n",
        "  errors = abs(predictions - test_labels)\r\n",
        "  mape = 100 * np.mean(errors / test_labels)\r\n",
        "  accuracy = 100 - mape\r\n",
        "  print('Model Performance')\r\n",
        "  print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\r\n",
        "  print('Accuracy = {:0.2f}%.'.format(accuracy))\r\n",
        "    \r\n",
        "  return accuracy\r\n",
        "\r\n",
        "\r\n",
        "evaluate(random_search_cv, X_preprocessed, y_train)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Average Error: 0.4441 degrees.\n",
            "Accuracy = 94.52%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.52119273762196"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "metadata": {
        "id": "AK6dZv3AqBNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a Pipeline"
      ],
      "metadata": {
        "id": "pw853VjebsIu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "source": [
        "\r\n",
        "my_pipeline = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('preprocessor', preprocessor),\r\n",
        "      ('model', RandomForestRegressor(\r\n",
        "                  n_estimators=300,\r\n",
        "                  random_state=0,\r\n",
        "                  min_samples_split=10,\r\n",
        "                  min_samples_leaf=8,\r\n",
        "                  n_jobs=-1,\r\n",
        "                  max_features= 'sqrt',\r\n",
        "                  max_depth=30,\r\n",
        "                  bootstrap=True,\r\n",
        "                )\r\n",
        "      ),\r\n",
        "    ]\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "WlZvv025bvOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the Model"
      ],
      "metadata": {
        "id": "h3B5mTAocG5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "source": [
        "my_pipeline.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent')),\n",
              "                                                                  ('ordinal',\n",
              "                                                                   OrdinalEncoder())]),\n",
              "                                                  ['cat1', 'cat5', 'cat8']),\n",
              "                                                 ('num',\n",
              "                                                  Pipeline(steps=[('simple',\n",
              "                                                                   SimpleImputer(strategy='constant'))]),\n",
              "                                                  ['cont0', 'cont1', 'cont2',\n",
              "                                                   'cont3', 'cont4', 'cont5',\n",
              "                                                   'cont6', 'cont7', 'cont8',\n",
              "                                                   'cont9', 'cont10', 'cont11',\n",
              "                                                   'cont12', 'cont13'])])),\n",
              "                ('model',\n",
              "                 RandomForestRegressor(max_depth=30, max_features='sqrt',\n",
              "                                       min_samples_leaf=8, min_samples_split=10,\n",
              "                                       n_estimators=300, n_jobs=-1,\n",
              "                                       random_state=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjtLCzNxcI0g",
        "outputId": "bc356d9c-7d92-442b-c2e0-0ec498bbecec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Step 5: Evaluate Our Model**\n"
      ],
      "metadata": {
        "id": "w1rLLfu1cYXb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "source": [
        "# Generate predictions on the validation set:\r\n",
        "pred_validate = my_pipeline.predict(X_validate)\r\n",
        "\r\n",
        "# Score Our Predictions -- using mean root squared error\r\n",
        "mse = mean_squared_error(y_validate, pred_validate, squared=False)\r\n",
        "\r\n",
        "print(\"MSE: \", round(mse, 7))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  0.7333595\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5-IQxyvci_4",
        "outputId": "e8c49da2-85a7-419c-dc9c-d182db4925a3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Determine Feature Importance"
      ],
      "metadata": {
        "id": "4321qGE5eACR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Final Step: Create the Submission File**"
      ],
      "metadata": {
        "id": "q7ebkp2ieZ9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "source": [
        "X_test = X_test.drop(dropped_features, axis=1)\r\n",
        "\r\n",
        "# Use the model to make predictions:\r\n",
        "predictions = my_pipeline.predict(X_test)\r\n",
        "\r\n",
        "# Save the predictions to a CSV file:\r\n",
        "output = pd.DataFrame({\r\n",
        "    'Id': X_test.index,\r\n",
        "    'target': predictions,\r\n",
        "})\r\n",
        "\r\n",
        "output.to_csv(\"submission.csv\", index=False)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "n2gut3YEeftg"
      }
    }
  ]
}