{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Random Forest Regressor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit ('env': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "0111817ea0767685089815a8346b7ddb44dc6686759b000d5a9694abd8ceb5ac"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 30 Days of ML Competition\r\n",
        "---"
      ],
      "metadata": {
        "id": "Ok47I272TGWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Import Libraries**"
      ],
      "metadata": {
        "id": "i7_V_KauUKsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "#!pip install numpy pandas scikit-learn xgboost keras --quiet"
      ],
      "outputs": [],
      "metadata": {
        "id": "v35wezvpSJDJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score, KFold,\r\n",
        "                                     RandomizedSearchCV, GridSearchCV)\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "\r\n",
        "from xgboost import XGBRegressor\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "INYJMKCNTN1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\r\n",
        "\r\n",
        "### **Step 2: Load the Data**\r\n"
      ],
      "metadata": {
        "id": "KcsIaChVUTf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# Load the training data:\r\n",
        "training_df = pd.read_csv(\"data/train.csv\", index_col=0)\r\n",
        "testing_df = pd.read_csv(\"data/test.csv\", index_col=0)\r\n",
        "\r\n",
        "# Preview the data:\r\n",
        "print(training_df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont5     cont6  \\\n",
            "id                                                    ...                       \n",
            "1     B    B    B    C    B    B    A    E    C    N  ...  0.400361  0.160266   \n",
            "2     B    B    A    A    B    D    A    F    A    O  ...  0.533087  0.558922   \n",
            "3     A    A    A    C    B    D    A    D    A    F  ...  0.650609  0.375348   \n",
            "4     B    B    A    C    B    D    A    E    C    K  ...  0.668980  0.239061   \n",
            "6     A    A    A    C    B    D    A    E    A    N  ...  0.686964  0.420667   \n",
            "\n",
            "       cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
            "id                                                                         \n",
            "1   0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n",
            "2   0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n",
            "3   0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n",
            "4   0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n",
            "6   0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n",
            "\n",
            "      target  \n",
            "id            \n",
            "1   8.113634  \n",
            "2   8.481233  \n",
            "3   8.364351  \n",
            "4   8.049253  \n",
            "6   7.972260  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51JC1MlbUZeD",
        "outputId": "75a3cc3f-d515-4459-d2a7-6def6b99710f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "\r\n",
        "# Seperate the Data from the Target:\r\n",
        "y = training_df[\"target\"]\r\n",
        "features = training_df.drop([\"target\"], axis=1)\r\n",
        "\r\n",
        "# Drop noise features:\r\n",
        "dropped_features = [\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat6\", \"cat7\", 'cat9']\r\n",
        "features = features.drop(dropped_features, axis=1)\r\n",
        "\r\n",
        "#Add features:\r\n",
        "features[\"cat1_A\"] = training_df[\"cat1\"].apply(lambda x: 1 if x == \"A\" else 0)\r\n",
        "features[\"cat8_C\"] = training_df[\"cat8\"].apply(lambda x: 1 if x == \"C\" else 0)\r\n",
        "features[\"cat8_E\"] = training_df[\"cat8\"].apply(lambda x: 1 if x == \"E\" else 0)\r\n",
        "\r\n",
        "\r\n",
        "print(features.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cat5 cat8     cont0     cont1     cont2     cont3     cont4     cont5  \\\n",
            "id                                                                         \n",
            "1     B    C  0.201470 -0.014822  0.669699  0.136278  0.610706  0.400361   \n",
            "2     D    A  0.743068  0.367411  1.021605  0.365798  0.276853  0.533087   \n",
            "3     D    A  0.742708  0.310383 -0.012673  0.576957  0.285074  0.650609   \n",
            "4     D    C  0.429551  0.620998  0.577942  0.280610  0.284667  0.668980   \n",
            "6     D    A  1.058291  0.367492 -0.052389  0.232407  0.287595  0.686964   \n",
            "\n",
            "       cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
            "id                                                                         \n",
            "1   0.160266  0.310921  0.389470  0.267559  0.237281  0.377873  0.322401   \n",
            "2   0.558922  0.516294  0.594928  0.341439  0.906013  0.921701  0.261975   \n",
            "3   0.375348  0.902567  0.555205  0.843531  0.748809  0.620126  0.541474   \n",
            "4   0.239061  0.732948  0.679618  0.574844  0.346010  0.714610  0.540150   \n",
            "6   0.420667  0.648182  0.684501  0.956692  1.000773  0.776742  0.625849   \n",
            "\n",
            "      cont13  cat1_A  cat8_C  cat8_E  \n",
            "id                                    \n",
            "1   0.869850       0       1       0  \n",
            "2   0.465083       0       0       0  \n",
            "3   0.763846       1       0       0  \n",
            "4   0.280682       0       1       0  \n",
            "6   0.250823       1       0       0  \n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5AgJfZJVmza",
        "outputId": "507b0ef1-8cc3-4fa2-c875-ff7048e9c7cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\r\n",
        "### **Step 3: Prepare the Data**"
      ],
      "metadata": {
        "id": "jg1-Lf-zWJx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seperate Our Variable Types:"
      ],
      "metadata": {
        "id": "GHl8lcveYdP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# List of the categorical columns:\r\n",
        "#categorical_cols = [col for col in features.columns if 'cat' in col]\r\n",
        "categorical_cols = ['cat5', 'cat8']\r\n",
        "\r\n",
        "#-----------------------------------------------------------------------\r\n",
        "\r\n",
        "# List of the numerical columns:\r\n",
        "number_cols = [col for col in features.columns if 'cat' not in col]\r\n",
        "\r\n",
        "#-----------------------------------------------------------------------\r\n",
        "\r\n",
        "# Additional binary features:\r\n",
        "binary_cols = ['cat1_A', 'cat8_C', 'cat8_E']"
      ],
      "outputs": [],
      "metadata": {
        "id": "VKFo3aEZWO_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Preproprocessing Transformers"
      ],
      "metadata": {
        "id": "AkHORuzuYjnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Preprocess categorical data:\r\n",
        "category_transformer = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('imputer', SimpleImputer(strategy='most_frequent')),\r\n",
        "      ('ordinal', OrdinalEncoder()),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "# Preprocess numerical data:\r\n",
        "number_transformer = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('simple', SimpleImputer(strategy='constant')),\r\n",
        "    ]\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "WH-o1zczYg2B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Combine the preprocessing steps into column transformer:\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "      ('cat', category_transformer, categorical_cols),\r\n",
        "      ('num', number_transformer, number_cols),\r\n",
        "    ]\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Oy-VqAyhZ74T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Copy Our DataFrames"
      ],
      "metadata": {
        "id": "AYbiLJlZaH7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "X = features.copy()\r\n",
        "X_test = testing_df.copy()\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "KFG_FJvTaMrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the Data Into Training & Validation Sets"
      ],
      "metadata": {
        "id": "FlpqGgLgaWpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Split data:\r\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(\r\n",
        "    X, y,\r\n",
        "    test_size=0.25,\r\n",
        "    random_state=0\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "SavCpBIuabO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Step 4: Setting Up & Training the Model**"
      ],
      "metadata": {
        "id": "cIuOmR1cbGu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "\r\n",
        "# Create the random grid:\r\n",
        "params = {\r\n",
        "        'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05],\r\n",
        "}\r\n",
        "\r\n",
        "print(params)\r\n",
        "\r\n",
        "X_validate_processed = preprocessor.fit_transform(X_validate)\r\n",
        "# Configure the model to use GPU:\r\n",
        "xgb_reg = XGBRegressor(\r\n",
        "    n_estimators=1160,\r\n",
        "    learning_rate=0.03,\r\n",
        "    min_split_loss=0.06,\r\n",
        "    colsample_bytree=0.3,\r\n",
        "    objective='reg:squarederror',\r\n",
        "    subsample=0.85,\r\n",
        "    tree_method='gpu_hist',\r\n",
        "    gpu_id=0,\r\n",
        ")\r\n",
        "\r\n",
        "# Random search of parameters, using 3 fold cross validation\r\n",
        "xgb_grid = GridSearchCV(\r\n",
        "    estimator=xgb_reg,\r\n",
        "    param_grid=params,\r\n",
        "    scoring='neg_root_mean_squared_error',\r\n",
        "    cv=2,\r\n",
        "    verbose=2,\r\n",
        "    n_jobs=-1,\r\n",
        ")\r\n",
        "\r\n",
        "# Preprocess training data:\r\n",
        "X_processed = preprocessor.fit_transform(X_train)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05]}\n"
          ]
        }
      ],
      "metadata": {
        "id": "Mcc6HC8UbQ8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "# Fit the Random Search model:\r\n",
        "xgb_grid.fit(X_processed, y_train)\r\n",
        "\r\n",
        "# See the best params from fitting the random search:\r\n",
        "print(xgb_grid.best_params_)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [-0.72678559 -0.73112011         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 10}\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp_-7WnroBMO",
        "outputId": "f2c97d6d-89a6-4e16-f98c-d05485df28c5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "# Evaluate the random search model:\r\n",
        "def evaluate(model, test_features, test_labels):\r\n",
        "  predictions = model.predict(test_features)\r\n",
        "  errors = abs(predictions - test_labels)\r\n",
        "  mape = 100 * np.mean(errors / test_labels)\r\n",
        "  accuracy = 100 - mape\r\n",
        "  print('Model Performance')\r\n",
        "  print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\r\n",
        "  print('Accuracy = {:0.2f}%.'.format(accuracy))\r\n",
        "    \r\n",
        "  return accuracy\r\n",
        "\r\n",
        "\r\n",
        "evaluate(xgb_grid, X_processed, y_train)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Average Error: 0.4114 degrees.\n",
            "Accuracy = 94.95%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.94966440535256"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "metadata": {
        "id": "AK6dZv3AqBNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a Pipeline"
      ],
      "metadata": {
        "id": "pw853VjebsIu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "source": [
        "\r\n",
        "my_pipeline = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('preprocessor', preprocessor),\r\n",
        "      ('model', XGBRegressor(\r\n",
        "                  n_estimators=1160,\r\n",
        "                  learning_rate=0.03,\r\n",
        "                  random_state=0,\r\n",
        "                  n_jobs=-1,\r\n",
        "                  subsample=0.85,\r\n",
        "                  colsample_bytree=0.3,\r\n",
        "                  min_child_weight=22,\r\n",
        "                  min_split_loss=0.06,\r\n",
        "                  tree_method='gpu_hist',\r\n",
        "                  gpu_id=0\r\n",
        "                )\r\n",
        "      ),\r\n",
        "    ]\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "WlZvv025bvOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the Model"
      ],
      "metadata": {
        "id": "h3B5mTAocG5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "my_pipeline.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "[18:15:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:103: label must be in [0,1] for logistic regression",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8740/180330879.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    737\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
            "\u001b[1;32mc:\\Users\\Evan\\Documents\\GitHub\\30-Days-Of-ML-Competition\\env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mXGBoostError\u001b[0m: [18:15:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:103: label must be in [0,1] for logistic regression"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjtLCzNxcI0g",
        "outputId": "bc356d9c-7d92-442b-c2e0-0ec498bbecec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Step 5: Evaluate Our Model**\n"
      ],
      "metadata": {
        "id": "w1rLLfu1cYXb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "# Generate predictions on the validation set:\r\n",
        "pred_validate = my_pipeline.predict(X_validate)\r\n",
        "\r\n",
        "# Score Our Predictions -- using mean root squared error\r\n",
        "mse = mean_squared_error(y_validate, pred_validate, squared=False)\r\n",
        "\r\n",
        "print(\"MSE: \", round(mse, 7))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  0.7240738\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5-IQxyvci_4",
        "outputId": "e8c49da2-85a7-419c-dc9c-d182db4925a3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Determine Feature Importance"
      ],
      "metadata": {
        "id": "4321qGE5eACR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Final Step: Create the Submission File**"
      ],
      "metadata": {
        "id": "q7ebkp2ieZ9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "X_test = X_test.drop(dropped_features, axis=1)\r\n",
        "#Add features:\r\n",
        "X_test[\"cat1_A\"] = testing_df[\"cat1\"].apply(lambda x: 1 if x == \"A\" else 0)\r\n",
        "X_test[\"cat8_C\"] = testing_df[\"cat8\"].apply(lambda x: 1 if x == \"C\" else 0)\r\n",
        "X_test[\"cat8_E\"] = testing_df[\"cat8\"].apply(lambda x: 1 if x == \"E\" else 0)\r\n",
        "\r\n",
        "\r\n",
        "# Use the model to make predictions:\r\n",
        "predictions = my_pipeline.predict(X_test)\r\n",
        "\r\n",
        "# Save the predictions to a CSV file:\r\n",
        "output = pd.DataFrame({\r\n",
        "    'Id': X_test.index,\r\n",
        "    'target': predictions,\r\n",
        "})\r\n",
        "\r\n",
        "output.to_csv(\"submission.csv\", index=False)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "n2gut3YEeftg"
      }
    }
  ]
}