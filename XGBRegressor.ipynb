{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Random Forest Regressor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit ('env': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "0111817ea0767685089815a8346b7ddb44dc6686759b000d5a9694abd8ceb5ac"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 30 Days of ML Competition\n",
        "---"
      ],
      "metadata": {
        "id": "Ok47I272TGWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Import Libraries**"
      ],
      "metadata": {
        "id": "i7_V_KauUKsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#!pip install numpy pandas scikit-learn xgboost keras --quiet"
      ],
      "outputs": [],
      "metadata": {
        "id": "v35wezvpSJDJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score, KFold,\r\n",
        "                                     RandomizedSearchCV, GridSearchCV)\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "\r\n",
        "from xgboost import XGBRegressor\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "INYJMKCNTN1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Step 2: Load the Data**\n"
      ],
      "metadata": {
        "id": "KcsIaChVUTf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "# Load the training data:\r\n",
        "training_df = pd.read_csv(\"data/train.csv\", index_col=0)\r\n",
        "testing_df = pd.read_csv(\"data/test.csv\", index_col=0)\r\n",
        "\r\n",
        "# Preview the data:\r\n",
        "print(training_df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont5     cont6  \\\n",
            "id                                                    ...                       \n",
            "1     B    B    B    C    B    B    A    E    C    N  ...  0.400361  0.160266   \n",
            "2     B    B    A    A    B    D    A    F    A    O  ...  0.533087  0.558922   \n",
            "3     A    A    A    C    B    D    A    D    A    F  ...  0.650609  0.375348   \n",
            "4     B    B    A    C    B    D    A    E    C    K  ...  0.668980  0.239061   \n",
            "6     A    A    A    C    B    D    A    E    A    N  ...  0.686964  0.420667   \n",
            "\n",
            "       cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
            "id                                                                         \n",
            "1   0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n",
            "2   0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n",
            "3   0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n",
            "4   0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n",
            "6   0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n",
            "\n",
            "      target  \n",
            "id            \n",
            "1   8.113634  \n",
            "2   8.481233  \n",
            "3   8.364351  \n",
            "4   8.049253  \n",
            "6   7.972260  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51JC1MlbUZeD",
        "outputId": "75a3cc3f-d515-4459-d2a7-6def6b99710f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "\r\n",
        "# Seperate the Data from the Target:\r\n",
        "y = training_df[\"target\"]\r\n",
        "features = training_df.drop([\"target\"], axis=1)\r\n",
        "\r\n",
        "# Drop noise features:\r\n",
        "dropped_features = [\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat6\", \"cat7\", 'cat9']\r\n",
        "features = features.drop(dropped_features, axis=1)\r\n",
        "\r\n",
        "#Add features:\r\n",
        "features[\"cat1_A\"] = training_df[\"cat1\"].apply(lambda x: 1 if x == \"A\" else 0)\r\n",
        "features[\"cat8_C\"] = training_df[\"cat8\"].apply(lambda x: 1 if x == \"C\" else 0)\r\n",
        "features[\"cat8_E\"] = training_df[\"cat8\"].apply(lambda x: 1 if x == \"E\" else 0)\r\n",
        "\r\n",
        "\r\n",
        "print(features.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cat5 cat8     cont0     cont1     cont2     cont3     cont4     cont5  \\\n",
            "id                                                                         \n",
            "1     B    C  0.201470 -0.014822  0.669699  0.136278  0.610706  0.400361   \n",
            "2     D    A  0.743068  0.367411  1.021605  0.365798  0.276853  0.533087   \n",
            "3     D    A  0.742708  0.310383 -0.012673  0.576957  0.285074  0.650609   \n",
            "4     D    C  0.429551  0.620998  0.577942  0.280610  0.284667  0.668980   \n",
            "6     D    A  1.058291  0.367492 -0.052389  0.232407  0.287595  0.686964   \n",
            "\n",
            "       cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
            "id                                                                         \n",
            "1   0.160266  0.310921  0.389470  0.267559  0.237281  0.377873  0.322401   \n",
            "2   0.558922  0.516294  0.594928  0.341439  0.906013  0.921701  0.261975   \n",
            "3   0.375348  0.902567  0.555205  0.843531  0.748809  0.620126  0.541474   \n",
            "4   0.239061  0.732948  0.679618  0.574844  0.346010  0.714610  0.540150   \n",
            "6   0.420667  0.648182  0.684501  0.956692  1.000773  0.776742  0.625849   \n",
            "\n",
            "      cont13  cat1_A  cat8_C  cat8_E  \n",
            "id                                    \n",
            "1   0.869850       0       1       0  \n",
            "2   0.465083       0       0       0  \n",
            "3   0.763846       1       0       0  \n",
            "4   0.280682       0       1       0  \n",
            "6   0.250823       1       0       0  \n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5AgJfZJVmza",
        "outputId": "507b0ef1-8cc3-4fa2-c875-ff7048e9c7cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Step 3: Prepare the Data**"
      ],
      "metadata": {
        "id": "jg1-Lf-zWJx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seperate Our Variable Types:"
      ],
      "metadata": {
        "id": "GHl8lcveYdP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "# List of the categorical columns:\r\n",
        "#categorical_cols = [col for col in features.columns if 'cat' in col]\r\n",
        "categorical_cols = ['cat5', 'cat8']\r\n",
        "\r\n",
        "#-----------------------------------------------------------------------\r\n",
        "\r\n",
        "# List of the numerical columns:\r\n",
        "number_cols = [col for col in features.columns if 'cat' not in col]\r\n",
        "\r\n",
        "#-----------------------------------------------------------------------\r\n",
        "\r\n",
        "# Additional binary features:\r\n",
        "binary_cols = ['cat1_A', 'cat8_C', 'cat8_E']"
      ],
      "outputs": [],
      "metadata": {
        "id": "VKFo3aEZWO_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Preproprocessing Transformers"
      ],
      "metadata": {
        "id": "AkHORuzuYjnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Preprocess categorical data:\r\n",
        "category_transformer = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('imputer', SimpleImputer(strategy='most_frequent')),\r\n",
        "      ('ordinal', OrdinalEncoder()),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "# Preprocess numerical data:\r\n",
        "number_transformer = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('simple', SimpleImputer(strategy='constant')),\r\n",
        "    ]\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "WH-o1zczYg2B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Combine the preprocessing steps into column transformer:\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "      ('cat', category_transformer, categorical_cols),\r\n",
        "      ('num', number_transformer, number_cols),\r\n",
        "    ]\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Oy-VqAyhZ74T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Copy Our DataFrames"
      ],
      "metadata": {
        "id": "AYbiLJlZaH7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "X = features.copy()\r\n",
        "X_test = testing_df.copy()\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "KFG_FJvTaMrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the Data Into Training & Validation Sets"
      ],
      "metadata": {
        "id": "FlpqGgLgaWpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Split data:\r\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(\r\n",
        "    X, y,\r\n",
        "    test_size=0.25,\r\n",
        "    random_state=0\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "SavCpBIuabO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Step 4: Setting Up & Training the Model**"
      ],
      "metadata": {
        "id": "cIuOmR1cbGu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "#Resource: https://www.kaggle.com/felipefiorini/xgboost-hyper-parameter-tuning\r\n",
        "\r\n",
        "# Create the random grid:\r\n",
        "params = {\r\n",
        "        'learning_rate': [0.03],\r\n",
        "        #'max_depth': [3, 5, 7, 10, 15, 20],\r\n",
        "        'min_split_loss': [0.06],\r\n",
        "        #'min_child_weight': [5, 7, 10, 15, 20],\r\n",
        "        'subsample': [0.75, 0.85],\r\n",
        "        'colsample_bytree': [0.3, 0.5, 0.7, 0.9],\r\n",
        "        'n_estimators' : [1000],\r\n",
        "        'objective': ['reg:squarederror']\r\n",
        "    }\r\n",
        "\r\n",
        "print(params)\r\n",
        "\r\n",
        "X_validate_processed = preprocessor.fit_transform(X_validate)\r\n",
        "# Configure the model to use GPU:\r\n",
        "xgb_reg = XGBRegressor(n_estimators=1000,\r\n",
        "                       learning_rate=0.03,\r\n",
        "                       tree_method='gpu_hist',\r\n",
        "                       gpu_id=0,\r\n",
        "                       early_stopping_rounds=10,\r\n",
        "                       eval_set=([X_validate_processed, y_validate]),\r\n",
        ")\r\n",
        "\r\n",
        "# Random search of parameters, using 3 fold cross validation\r\n",
        "xgb_grid = GridSearchCV(\r\n",
        "    estimator=xgb_reg,\r\n",
        "    param_grid=params,\r\n",
        "    scoring='neg_root_mean_squared_error',\r\n",
        "    cv=2,\r\n",
        "    verbose=2,\r\n",
        "    n_jobs=-1,\r\n",
        ")\r\n",
        "\r\n",
        "# Preprocess training data:\r\n",
        "X_processed = preprocessor.fit_transform(X_train)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': [0.03], 'min_split_loss': [0.06], 'subsample': [0.75, 0.85], 'colsample_bytree': [0.3, 0.5, 0.7, 0.9], 'n_estimators': [1000], 'objective': ['reg:squarederror']}\n"
          ]
        }
      ],
      "metadata": {
        "id": "Mcc6HC8UbQ8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "# Fit the Random Search model:\r\n",
        "xgb_grid.fit(X_processed, y_train)\r\n",
        "\r\n",
        "# See the best params from fitting the random search:\r\n",
        "print(xgb_grid.best_params_)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "[20:20:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
            "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
            "\n",
            "  This may not be accurate due to some parameters are only used in language bindings but\n",
            "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
            "  verification. Please open an issue if you find above cases.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp_-7WnroBMO",
        "outputId": "f2c97d6d-89a6-4e16-f98c-d05485df28c5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "# Evaluate the random search model:\r\n",
        "def evaluate(model, test_features, test_labels):\r\n",
        "  predictions = model.predict(test_features)\r\n",
        "  errors = abs(predictions - test_labels)\r\n",
        "  mape = 100 * np.mean(errors / test_labels)\r\n",
        "  accuracy = 100 - mape\r\n",
        "  print('Model Performance')\r\n",
        "  print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\r\n",
        "  print('Accuracy = {:0.2f}%.'.format(accuracy))\r\n",
        "    \r\n",
        "  return accuracy\r\n",
        "\r\n",
        "\r\n",
        "evaluate(xgb_grid, X_processed, y_train)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Average Error: 0.5441 degrees.\n",
            "Accuracy = 93.30%.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93.30308197432988"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "metadata": {
        "id": "AK6dZv3AqBNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a Pipeline"
      ],
      "metadata": {
        "id": "pw853VjebsIu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "\r\n",
        "my_pipeline = Pipeline(\r\n",
        "    steps=[\r\n",
        "      ('preprocessor', preprocessor),\r\n",
        "      ('model', XGBRegressor(\r\n",
        "                  n_estimators=1000,\r\n",
        "                  learning_rate=0.03,\r\n",
        "                  random_state=0,\r\n",
        "                  n_jobs=-1,\r\n",
        "                  early_stopping_rounds=10,\r\n",
        "                  eval_set=([X_validate_processed, y_validate]),\r\n",
        "                  subsample=0.85,\r\n",
        "                  min_child_weight=5,\r\n",
        "                  min_split_loss=0.06,\r\n",
        "                  tree_method='gpu_hist',\r\n",
        "                  gpu_id=0\r\n",
        "                )\r\n",
        "      ),\r\n",
        "    ]\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "WlZvv025bvOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the Model"
      ],
      "metadata": {
        "id": "h3B5mTAocG5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "my_pipeline.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
            "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
            "\n",
            "  This may not be accurate due to some parameters are only used in language bindings but\n",
            "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
            "  verification. Please open an issue if you find above cases.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent')),\n",
              "                                                                  ('ordinal',\n",
              "                                                                   OrdinalEncoder())]),\n",
              "                                                  ['cat5', 'cat8']),\n",
              "                                                 ('num',\n",
              "                                                  Pipeline(steps=[('simple',\n",
              "                                                                   SimpleImputer(strategy='constant'))]),\n",
              "                                                  ['cont0', 'cont1', 'cont2',\n",
              "                                                   'cont3', 'cont4', 'cont5',\n",
              "                                                   'cont6', 'cont7', 'cont8',\n",
              "                                                   'cont9', 'cont10', 'c...\n",
              "                              importance_type='gain',\n",
              "                              interaction_constraints='', learning_rate=0.03,\n",
              "                              max_delta_step=0, max_depth=6, min_child_weight=5,\n",
              "                              min_split_loss=0.06, missing=nan,\n",
              "                              monotone_constraints='()', n_estimators=1000,\n",
              "                              n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
              "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                              subsample=0.85, tree_method='gpu_hist',\n",
              "                              validate_parameters=1, verbosity=None))])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjtLCzNxcI0g",
        "outputId": "bc356d9c-7d92-442b-c2e0-0ec498bbecec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Step 5: Evaluate Our Model**\n"
      ],
      "metadata": {
        "id": "w1rLLfu1cYXb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "# Generate predictions on the validation set:\r\n",
        "pred_validate = my_pipeline.predict(X_validate)\r\n",
        "\r\n",
        "# Score Our Predictions -- using mean root squared error\r\n",
        "mse = mean_squared_error(y_validate, pred_validate, squared=False)\r\n",
        "\r\n",
        "print(\"MSE: \", round(mse, 7))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  0.7242048\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5-IQxyvci_4",
        "outputId": "e8c49da2-85a7-419c-dc9c-d182db4925a3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Determine Feature Importance"
      ],
      "metadata": {
        "id": "4321qGE5eACR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Final Step: Create the Submission File**"
      ],
      "metadata": {
        "id": "q7ebkp2ieZ9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "X_test = X_test.drop(dropped_features, axis=1)\r\n",
        "#Add features:\r\n",
        "X_test[\"cat1_A\"] = testing_df[\"cat1\"].apply(lambda x: 1 if x == \"A\" else 0)\r\n",
        "X_test[\"cat8_C\"] = testing_df[\"cat8\"].apply(lambda x: 1 if x == \"C\" else 0)\r\n",
        "X_test[\"cat8_E\"] = testing_df[\"cat8\"].apply(lambda x: 1 if x == \"E\" else 0)\r\n",
        "\r\n",
        "\r\n",
        "# Use the model to make predictions:\r\n",
        "predictions = my_pipeline.predict(X_test)\r\n",
        "\r\n",
        "# Save the predictions to a CSV file:\r\n",
        "output = pd.DataFrame({\r\n",
        "    'Id': X_test.index,\r\n",
        "    'target': predictions,\r\n",
        "})\r\n",
        "\r\n",
        "output.to_csv(\"submission.csv\", index=False)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "n2gut3YEeftg"
      }
    }
  ]
}